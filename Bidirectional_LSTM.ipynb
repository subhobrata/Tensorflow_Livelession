{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Bidirectional_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhobrata/Tensorflow_Livelession/blob/master/Bidirectional_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-sukRwLn0iS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebd5946b-e33a-409d-c515-fde458b430b2"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
        "from keras.layers.wrappers import Bidirectional # new! \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Tgm_oPD0q7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7a31056d-bb42-4a94-f765-875553f1fe7b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5QF_TdQ52Ew3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# output directory name:\n",
        "output_dir = '/content/gdrive/My Drive/data/'\n",
        "\n",
        "# training:\n",
        "epochs = 6\n",
        "batch_size = 128\n",
        "\n",
        "# vector-space embedding: \n",
        "n_dim = 64 \n",
        "n_unique_words = 10000 \n",
        "max_review_length = 200 # doubled!\n",
        "pad_type = trunc_type = 'pre'\n",
        "drop_embed = 0.2 \n",
        "\n",
        "# LSTM layer architecture:\n",
        "n_lstm = 256 \n",
        "drop_lstm = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E0ZJ4_Tw2W3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14ca5a42-599d-4575-cdb1-129d75ebe1ed"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nzpnRcT72bBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
        "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IfNXDNVm2d8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "27f4b55d-fdd0-4843-8b1e-7b9c26a9997d"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
        "model.add(SpatialDropout1D(drop_embed))\n",
        "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DCtqWzHv2hie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "beec42e2-2ba0-403e-b32d-17bf6248f10c"
      },
      "cell_type": "code",
      "source": [
        "# LSTM layer parameters double due to both reading directions\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 64)           640000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 200, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               657408    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,297,921\n",
            "Trainable params: 1,297,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uQpyXdmJ2kLz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQZ-3l3n2nIN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "it5k95jd2qMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "95b97d14-43a6-4457-e5c4-ddc757d34f8e"
      },
      "cell_type": "code",
      "source": [
        "# - we see 87.0% validation accuracy in epoch 2\n",
        "# - with this toy dataset, the complex interplay of words over long sentence segments, won't be learned much\n",
        "# - so our CNN picking up location-invariant segments of two to four words that predict review sentiment\n",
        "# - these are simpler and so easier to learn from the data\n",
        "# - CNN therefore outperforms on the IMDB data set\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/6\n",
            "25000/25000 [==============================] - 897s 36ms/step - loss: 0.5838 - acc: 0.6752 - val_loss: 0.3892 - val_acc: 0.8272\n",
            "Epoch 2/6\n",
            "25000/25000 [==============================] - 899s 36ms/step - loss: 0.3070 - acc: 0.8731 - val_loss: 0.3322 - val_acc: 0.8662\n",
            "Epoch 3/6\n",
            "25000/25000 [==============================] - 901s 36ms/step - loss: 0.2266 - acc: 0.9124 - val_loss: 0.3486 - val_acc: 0.8491\n",
            "Epoch 4/6\n",
            "25000/25000 [==============================] - 899s 36ms/step - loss: 0.1880 - acc: 0.9296 - val_loss: 0.3242 - val_acc: 0.8640\n",
            "Epoch 5/6\n",
            "24960/25000 [============================>.] - ETA: 1s - loss: 0.1483 - acc: 0.9468"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWsyoTN75SUa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_weights(output_dir+\"/weights.01.hdf5\") # zero-indexed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdO4qMOrHQ-g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_hat = model.predict_proba(x_valid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fZIbWa8HTbg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist(y_hat)\n",
        "_ = plt.axvline(x=0.5, color='orange')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FDgFt2QHWsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}